{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "006a5e5e-5942-4df8-8b19-5dfbb0ed1105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新闻聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5411036a-4ef0-4188-9373-2d62ea966967",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Requirement already satisfied: sentence-transformers in /opt/conda/lib/python3.8/site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.8/site-packages (1.3.1)\n",
      "Requirement already satisfied: langchain in /opt/conda/lib/python3.8/site-packages (0.0.348)\n",
      "Requirement already satisfied: unstructured in /opt/conda/lib/python3.8/site-packages (0.11.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.8/site-packages (from sentence-transformers) (4.34.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from sentence-transformers) (2.0.1+cu118)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.8/site-packages (from sentence-transformers) (0.15.2+cu118)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from sentence-transformers) (1.24.3)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from sentence-transformers) (1.10.1)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.8/site-packages (from sentence-transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.8/site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.8/site-packages (from sentence-transformers) (0.17.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.8/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.8/site-packages (from langchain) (2.0.23)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.8/site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.8/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.8/site-packages (from langchain) (0.6.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.8/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-core<0.1,>=0.0.12 in /opt/conda/lib/python3.8/site-packages (from langchain) (0.0.12)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /opt/conda/lib/python3.8/site-packages (from langchain) (0.0.69)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.8/site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.8/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.8/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: chardet in /opt/conda/lib/python3.8/site-packages (from unstructured) (5.2.0)\n",
      "Requirement already satisfied: filetype in /opt/conda/lib/python3.8/site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: python-magic in /opt/conda/lib/python3.8/site-packages (from unstructured) (0.4.27)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.8/site-packages (from unstructured) (4.9.3)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.8/site-packages (from unstructured) (0.9.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.8/site-packages (from unstructured) (4.12.2)\n",
      "Requirement already satisfied: emoji in /opt/conda/lib/python3.8/site-packages (from unstructured) (2.8.0)\n",
      "Requirement already satisfied: python-iso639 in /opt/conda/lib/python3.8/site-packages (from unstructured) (2023.6.15)\n",
      "Requirement already satisfied: langdetect in /opt/conda/lib/python3.8/site-packages (from unstructured) (1.0.9)\n",
      "Requirement already satisfied: rapidfuzz in /opt/conda/lib/python3.8/site-packages (from unstructured) (3.3.1)\n",
      "Requirement already satisfied: backoff in /opt/conda/lib/python3.8/site-packages (from unstructured) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from unstructured) (4.8.0)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.8/site-packages (from unstructured) (1.15.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.8/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.8/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.12.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.8/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.9.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.8/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in /opt/conda/lib/python3.8/site-packages (from langchain-core<0.1,>=0.0.12->langchain) (4.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.8/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.8/site-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.8/site-packages (from torch>=1.6.0->sentence-transformers) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/conda/lib/python3.8/site-packages (from torch>=1.6.0->sentence-transformers) (2.0.0)\n",
      "Requirement already satisfied: cmake in /opt/conda/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (3.27.2)\n",
      "Requirement already satisfied: lit in /opt/conda/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers) (16.0.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.8.8)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.8/site-packages (from beautifulsoup4->unstructured) (2.5)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from langdetect->unstructured) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from nltk->sentence-transformers) (8.1.7)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.8/site-packages (from torchvision->sentence-transformers) (10.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.8/site-packages (from anyio<5,>=3->langchain-core<0.1,>=0.0.12->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.8/site-packages (from anyio<5,>=3->langchain-core<0.1,>=0.0.12->langchain) (1.1.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.8/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.8/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install sentence-transformers scikit-learn langchain unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45c63f63-3d5c-40f6-b89c-877313c9703b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "获取:1 https://mirrors.aliyun.com/ubuntu focal InRelease [265 kB]\n",
      "获取:2 https://mirrors.aliyun.com/ubuntu focal-security InRelease [114 kB]       \n",
      "获取:3 https://mirrors.aliyun.com/ubuntu focal-updates InRelease [114 kB]        \n",
      "获取:4 https://mirrors.aliyun.com/ubuntu focal-backports InRelease [108 kB]      \n",
      "获取:5 https://mirrors.aliyun.com/ubuntu focal/universe amd64 Packages [11.3 MB] \n",
      "获取:6 https://mirrors.aliyun.com/ubuntu focal/main amd64 Packages [1,275 kB]    \n",
      "获取:7 https://mirrors.aliyun.com/ubuntu focal/multiverse amd64 Packages [177 kB]\n",
      "获取:8 https://mirrors.aliyun.com/ubuntu focal/restricted amd64 Packages [33.4 kB]\n",
      "获取:9 https://mirrors.aliyun.com/ubuntu focal-security/universe amd64 Packages [1,148 kB]\n",
      "获取:10 https://mirrors.aliyun.com/ubuntu focal-security/multiverse amd64 Packages [29.3 kB]\n",
      "获取:11 https://mirrors.aliyun.com/ubuntu focal-security/main amd64 Packages [3,245 kB]\n",
      "获取:12 https://mirrors.aliyun.com/ubuntu focal-security/restricted amd64 Packages [3,079 kB]\n",
      "获取:13 https://mirrors.aliyun.com/ubuntu focal-updates/multiverse amd64 Packages [32.0 kB]\n",
      "获取:14 https://mirrors.aliyun.com/ubuntu focal-updates/restricted amd64 Packages [3,272 kB]\n",
      "获取:15 https://mirrors.aliyun.com/ubuntu focal-updates/main amd64 Packages [3,754 kB]\n",
      "获取:16 https://mirrors.aliyun.com/ubuntu focal-updates/universe amd64 Packages [1,443 kB]\n",
      "获取:17 https://mirrors.aliyun.com/ubuntu focal-backports/universe amd64 Packages [28.6 kB]\n",
      "获取:18 https://mirrors.aliyun.com/ubuntu focal-backports/main amd64 Packages [55.2 kB]\n",
      "获取:19 https://developer.download.nvidia.cn/compute/cuda/repos/ubuntu2004/x86_64  InRelease [1,581 B]\n",
      "获取:20 https://developer.download.nvidia.cn/compute/cuda/repos/ubuntu2004/x86_64  Packages [1,313 kB]\n",
      "已下载 30.8 MB，耗时 3秒 (8,875 kB/s)       \n",
      "正在读取软件包列表... 完成%\n",
      "正在读取软件包列表... 完成%\n",
      "正在分析软件包的依赖关系树       \n",
      "正在读取状态信息... 完成         \n",
      "建议安装：\n",
      "  zip\n",
      "下列【新】软件包将被安装：\n",
      "  unzip\n",
      "升级了 0 个软件包，新安装了 1 个软件包， 要卸载 0 个软件包，有 84 个软件包未被升级。\n",
      "需要下载 168 kB 的归档。\n",
      "解压缩后会消耗 593 kB 的额外空间。\n",
      "获取:1 https://mirrors.aliyun.com/ubuntu focal-security/main amd64 unzip amd64 6.0-25ubuntu1.1 [168 kB]\n",
      "已下载 168 kB，耗时 0秒 (1,057 kB/s) \n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "正在选中未选择的软件包 unzip。\n",
      "(正在读取数据库 ... 系统当前共安装有 68739 个文件和目录。)\n",
      "准备解压 .../unzip_6.0-25ubuntu1.1_amd64.deb  ...\n",
      "正在解压 unzip (6.0-25ubuntu1.1) ...\n",
      "正在设置 unzip (6.0-25ubuntu1.1) ...\n",
      "正在处理用于 mime-support (3.64ubuntu1) 的触发器 ...\n",
      "Archive:  punkt.zip\n",
      "   creating: punkt/\n",
      "  inflating: punkt/greek.pickle      \n",
      "  inflating: punkt/estonian.pickle   \n",
      "  inflating: punkt/turkish.pickle    \n",
      "  inflating: punkt/polish.pickle     \n",
      "   creating: punkt/PY3/\n",
      "  inflating: punkt/PY3/greek.pickle  \n",
      "  inflating: punkt/PY3/estonian.pickle  \n",
      "  inflating: punkt/PY3/turkish.pickle  \n",
      "  inflating: punkt/PY3/polish.pickle  \n",
      "  inflating: punkt/PY3/russian.pickle  \n",
      "  inflating: punkt/PY3/czech.pickle  \n",
      "  inflating: punkt/PY3/portuguese.pickle  \n",
      "  inflating: punkt/PY3/README        \n",
      "  inflating: punkt/PY3/dutch.pickle  \n",
      "  inflating: punkt/PY3/norwegian.pickle  \n",
      "  inflating: punkt/PY3/slovene.pickle  \n",
      "  inflating: punkt/PY3/english.pickle  \n",
      "  inflating: punkt/PY3/danish.pickle  \n",
      "  inflating: punkt/PY3/finnish.pickle  \n",
      "  inflating: punkt/PY3/swedish.pickle  \n",
      "  inflating: punkt/PY3/spanish.pickle  \n",
      "  inflating: punkt/PY3/german.pickle  \n",
      "  inflating: punkt/PY3/italian.pickle  \n",
      "  inflating: punkt/PY3/french.pickle  \n",
      "  inflating: punkt/russian.pickle    \n",
      "  inflating: punkt/czech.pickle      \n",
      "  inflating: punkt/portuguese.pickle  \n",
      "  inflating: punkt/README            \n",
      "  inflating: punkt/dutch.pickle      \n",
      "  inflating: punkt/norwegian.pickle  \n",
      "  inflating: punkt/slovene.pickle    \n",
      "  inflating: punkt/english.pickle    \n",
      "  inflating: punkt/danish.pickle     \n",
      "  inflating: punkt/finnish.pickle    \n",
      "  inflating: punkt/swedish.pickle    \n",
      "  inflating: punkt/spanish.pickle    \n",
      "  inflating: punkt/german.pickle     \n",
      "  inflating: punkt/italian.pickle    \n",
      "  inflating: punkt/french.pickle     \n",
      "  inflating: punkt/.DS_Store         \n",
      "  inflating: punkt/PY3/malayalam.pickle  \n",
      "  inflating: punkt/malayalam.pickle  \n",
      "Archive:  averaged_perceptron_tagger.zip\n",
      "   creating: averaged_perceptron_tagger/\n",
      "  inflating: averaged_perceptron_tagger/averaged_perceptron_tagger.pickle  \n"
     ]
    }
   ],
   "source": [
    "# 手动下载nltk punkt、taggers，unstructured包需要\n",
    "!apt-get update\n",
    "!apt-get install unzip\n",
    "!unzip punkt.zip\n",
    "!unzip averaged_perceptron_tagger.zip\n",
    "!mkdir /root/nltk_data/\n",
    "!mkdir /root/nltk_data/tokenizers\n",
    "!mkdir /root/nltk_data/taggers\n",
    "!cp -r punkt/ /root/nltk_data/tokenizers\n",
    "!cp -r averaged_perceptron_tagger/ /root/nltk_data/taggers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bb0a1af-2b2c-416c-b2fb-56843b82e8cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.35s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.47s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.66s/it]\n"
     ]
    }
   ],
   "source": [
    "# 解析url结果\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "\n",
    "urls = {\n",
    "    '36kr': 'https://mp.weixin.qq.com/s/bz8hnmaX6tdbrmADELbrzQ',\n",
    "    'tencent': 'https://mp.weixin.qq.com/s/wvwIBrN6hczhiMIicK0SnA',\n",
    "    'bang': 'https://mp.weixin.qq.com/s/Gn6NZ9UtTF6Qy2SCOFf-KA'\n",
    "}\n",
    "\n",
    "def parse_url(url):\n",
    "    res = []\n",
    "    loader = UnstructuredURLLoader([url], mode='elements', show_progress_bar=True)\n",
    "    loader.requests_kwargs = {'verify':False}\n",
    "    elements = loader.load()\n",
    "\n",
    "    for element in elements:\n",
    "        res.append(element.page_content)\n",
    "    return res\n",
    "\n",
    "parse_texts = {}\n",
    "for source in urls:\n",
    "    source_url = urls[source]\n",
    "    parse_texts[source] = parse_url(source_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "792e2358-69b4-4e14-8955-d4d0ca6e091d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-11 13:25:42,046 - modelscope - INFO - PyTorch version 2.0.1+cu118 Found.\n",
      "2023-12-11 13:25:42,050 - modelscope - INFO - TensorFlow version 2.13.0 Found.\n",
      "2023-12-11 13:25:42,051 - modelscope - INFO - Loading ast index from /mnt/workspace/.cache/modelscope/ast_indexer\n",
      "2023-12-11 13:25:42,051 - modelscope - INFO - No valid ast index found from /mnt/workspace/.cache/modelscope/ast_indexer, generating ast index from prebuilt!\n",
      "2023-12-11 13:25:42,123 - modelscope - INFO - Loading done! Current index file version is 1.9.5, with md5 569b36a1f8cf6226713a963a2d3762a4 and a total number of 945 components indexed\n",
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-12-11 13:25:42,918 - modelscope - WARNING - Model revision not specified, use revision: v0.0.1\n",
      "Downloading: 100%|██████████| 191/191 [00:00<00:00, 31.7kB/s]\n",
      "Downloading: 100%|██████████| 0.98k/0.98k [00:00<00:00, 173kB/s]\n",
      "Downloading: 100%|██████████| 124/124 [00:00<00:00, 38.5kB/s]\n",
      "Downloading: 100%|██████████| 192/192 [00:00<00:00, 51.8kB/s]\n",
      "Downloading: 100%|█████████▉| 1.21G/1.21G [00:06<00:00, 216MB/s]\n",
      "Downloading: 100%|██████████| 349/349 [00:00<00:00, 95.3kB/s]\n",
      "Downloading: 100%|█████████▉| 1.21G/1.21G [00:05<00:00, 219MB/s]\n",
      "Downloading: 100%|██████████| 425/425 [00:00<00:00, 108kB/s]\n",
      "Downloading: 100%|██████████| 52.0/52.0 [00:00<00:00, 14.3kB/s]\n",
      "Downloading: 100%|██████████| 125/125 [00:00<00:00, 34.1kB/s]\n",
      "Downloading: 100%|██████████| 429k/429k [00:00<00:00, 26.8MB/s]\n",
      "Downloading: 100%|██████████| 394/394 [00:00<00:00, 108kB/s]\n",
      "Downloading: 100%|██████████| 107k/107k [00:00<00:00, 17.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "# 从ms上下载bge模型\n",
    "from modelscope import snapshot_download\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_path = snapshot_download('Xorbits/bge-large-zh-v1.5', cache_dir='bge')\n",
    "model = SentenceTransformer(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "17e01467-95e6-4483-ab4e-f7185fcee521",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 利用embedding，聚合title、passage\n",
    "import copy\n",
    "def segment(texts):\n",
    "    # 核心功能：list of text -> [title, passage1, passage2]\n",
    "    # 核心思想：对同一新闻来说，passage与title的相似度较大\n",
    "    news = []\n",
    "    one_new = []\n",
    "    title_embedding = None\n",
    "    \n",
    "    for text in texts:\n",
    "        text_embedding = model.encode(text, normalize_embeddings=True)\n",
    "        if title_embedding is None:\n",
    "            one_new.append(text)\n",
    "            title_embedding = text_embedding\n",
    "        else:\n",
    "            if (title_embedding @ text_embedding.T) > 0.5:\n",
    "                one_new.append(text)\n",
    "            else:\n",
    "                news.append(copy.deepcopy(one_new))\n",
    "                one_new = [text]\n",
    "                title_embedding = text_embedding\n",
    "\n",
    "    return news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3a55bb9f-49b8-4bcd-b919-a3a4986fd903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 进行切分，得到(title, passage)\n",
    "segments = {}\n",
    "for source in parse_texts:\n",
    "    segs = segment(parse_texts[source])\n",
    "    if source == '36kr':\n",
    "        segs = segs[3:-8]\n",
    "        segs = [seg for seg in segs if len(seg) > 1]\n",
    "    elif source == 'tencent':\n",
    "        segs = segs[2:-6]\n",
    "        segs = [seg for seg in segs if len(seg) > 1 and (len(seg[1]) - len(seg[0])) > 10]\n",
    "    elif source == 'bang':\n",
    "        segs = [seg for seg in segs if seg[0][0]=='【']\n",
    "    segments[source] = segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "0e5cd2ee-bd44-42fc-b1d8-9e0f8da4f5bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# segments['tencent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "aafc690e-6dad-41fc-b86b-8207f386db51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始进行clustering【针对title进行clustering】\n",
    "index2new = {}\n",
    "new_titles_embeddings = []\n",
    "index = 0\n",
    "for source in segments:\n",
    "    segs = segments[source]\n",
    "    for seg in segs:\n",
    "        title = seg[0]\n",
    "        passage = '\\n'.join(seg[1:])\n",
    "        new_titles_embeddings.append(model.encode(title, normalize_embeddings=True))\n",
    "        index2new[index] = [source, title, passage]\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "6c7ac192-6fe4-4d37-b762-e1605dbfec3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "import numpy as np\n",
    "\n",
    "X = np.array(new_titles_embeddings)\n",
    "clustering = DBSCAN(eps=0.3, min_samples=2, metric='cosine').fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "febb2437-059f-4679-959f-39b2087ddbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解析聚类结果\n",
    "clustering_res = {}\n",
    "for i, label in enumerate(clustering.labels_):\n",
    "    if label not in clustering_res:\n",
    "        clustering_res[label] = [index2new[i]]\n",
    "    else:\n",
    "        clustering_res[label].append(index2new[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "bb183c01-31f5-4b94-b442-84226a61c338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 0:\n",
      "\n",
      "from:36kr\n",
      "title:小米辟谣汽车发布会定档12月28日：有考虑这个时间，其他内容全是假的\n",
      "passage:小红书博主“电玩科技”9日发文，称小米内部已经“敲定”28日在北京举行小米汽车亮相发布会，将主要描述新车外观、内饰设计、性能操控、智能座舱及智能驾驶等方面的卖点，届时还会公布新车的预售价格。同时，雷军已经多次检查了现场用到的 PPT，并将亲自进行演讲。对此，汽车博主“电动扒士”联系小米汽车内部工作人员，对方表示：“时间还没定，确实在考虑这个时间点，其他内容全是假的。”（IT之家）\n",
      "\n",
      "from:bang\n",
      "title:【小米辟谣汽车发布会定档12月28日：有考虑这个时间，其他内容全是假的】\n",
      "passage:小红书博主“电玩科技”9日发文，称小米内部已经“敲定”28日在北京举行小米汽车亮相发布会，将主要描述新车外观、内饰设计、性能操控、智能座舱及智能驾驶等方面的卖点，届时还会公布新车的预售价格。同时，雷军已经多次检查了现场用到的 PPT，并将亲自进行演讲。对此，汽车博主@电动扒士联系小米汽车内部工作人员，对方表示：“时间还没定，确实在考虑这个时间点，其他内容全是假的。”（IT之家）\n",
      "\n",
      "##############################\n",
      "\n",
      "cluster 1:\n",
      "\n",
      "from:36kr\n",
      "title:元旦春节出行预订大幅上升，有平台酒店预订量同比增5倍\n",
      "passage:元旦假期的整体旅游预订量同比增长4倍，其中机票订单同比增长4倍，酒店预订量同比增长5倍。根据在线旅游平台数据显示，截至目前，元旦假期旅游热度同比上升181%。进入12月以来，元旦假期出行的旅游产品预订量环比增长57%，玩雪和避寒成为假期出行的两大主题。(央视新闻)\n",
      "\n",
      "from:bang\n",
      "title:【元旦春节出行预订大幅上升，有平台酒店预订量同比增5倍】\n",
      "passage:虽然距离2024年元旦春节还有一段时间，但是对假期出行的关注以及相关预订已经开始悄然升温。记者从在线旅游预订平台了解到，元旦假期的整体旅游预订量同比增长4倍，其中机票订单同比增长4倍，酒店预订量同比增长5倍。根据在线旅游平台数据显示，截至目前，元旦假期旅游热度同比上升181%。进入12月以来，元旦假期出行的旅游产品预订量环比增长57%，玩雪和避寒成为假期出行的两大主题。（财联社）\n",
      "\n",
      "##############################\n",
      "\n",
      "cluster 2:\n",
      "\n",
      "from:36kr\n",
      "title:马斯克的X被曝将与亚马逊合作：小型企业成为其广告业务目标客户\n",
      "passage:12月10日电，马斯克名下的社交平台X（前身为推特）日前因反犹争议而遭到大量广告商的抵制，但据消息人士称，X似乎已经找到了控制损失的办法。据悉，X正在与线上购物巨头亚马逊洽谈合作事宜，以将X平台的广告集成至亚马逊的广告购买软件中。这样一来，亚马逊的中小型商家或企业可以直接通过亚马逊购买X广告服务并在X上展示其商品。目前，该合作仍处于早期讨论阶段，仍有失败可能。X和亚马逊都没有对此事发表评论。（财联社）\n",
      "\n",
      "from:bang\n",
      "title:【马斯克的X被曝将与亚马逊合作：小型企业成为其广告业务目标客户】\n",
      "passage:马斯克名下的社交平台X（前身为推特）日前因反犹争议而遭到大量广告商的抵制，但据消息人士称，X似乎已经找到了控制损失的办法。据悉，X正在与线上购物巨头亚马逊洽谈合作事宜，以将X平台的广告集成至亚马逊的广告购买软件中。这样一来，亚马逊的中小型商家或企业可以直接通过亚马逊购买X 广告服务并在X上展示其商品。目前，该合作仍处于早期讨论阶段，仍有失败可能。X和亚马逊都没有对此事发表评论。（蓝鲸财经）\n",
      "\n",
      "##############################\n",
      "\n",
      "cluster 3:\n",
      "\n",
      "from:36kr\n",
      "title:乘联会崔东树：2023年乘用车销量预计达到2550万\n",
      "passage:12月10日，乘联会秘书长崔东树发文称，2023年11月乘用车市场零售达到208万辆，同比增长26%，环比增长2.4%。全年零售有望达到2150万台，同比增长5%，但较2017年峰值仍差220万台，加上出口的380万台，加上国内经销商库存因素，2023年乘用车销量预计达到2550万。依托出口相对2017年的320万增量，总体乘用车销量将大幅突破2017年的批发2450万台，创出历史新高。（选股宝）\n",
      "\n",
      "from:bang\n",
      "title:【乘联会崔东树：2023年乘用车销量预计达到2550万】\n",
      "passage:12月10日，乘联会秘书长崔东树发文称，2023年11月乘用车市场零售达到208万辆，同比增长26%，环比增长2.4%。全年零售有望达到2150万台，同比增长5%，但较2017年峰值仍差220万台，加上出口的380万台，加上国内经销商库存因素，2023年乘用车销量预计达到2550万。依托出口相对2017年的320万增量，总体乘用车销量将大幅突破2017年的批发2450万台，创出历史新高。（中新经纬）\n",
      "\n",
      "##############################\n",
      "\n",
      "cluster 4:\n",
      "\n",
      "from:36kr\n",
      "title:马斯克向OpenAl首席科学家抛出橄榄枝\n",
      "passage:OpenAI 首席科学家兼联合创始人伊尔亚・苏茨克维（Ilya Sutskever）目前正处于尴尬境地。上个月，他参与董事会投票解雇了CEO萨姆・阿尔特曼（Sam Altman），但仅仅五天后，阿尔特曼在员工和投资者的强烈支持下重新上任。最近的一篇报道指出，苏茨克维目前似乎处于一种“迷茫”的状态，在OpenAI变得“隐形”。报道称，自阿尔特曼回归以来，苏茨克维就没有出现在OpenAI旧金山的办公室内。就在人们纷纷猜测苏茨克维的未来走向时，马斯克在社交媒体上公开表示，苏茨克维应该加入特斯拉或他的AI公司xAI。（IT之家）\n",
      "\n",
      "from:tencent\n",
      "title:OpenAI首席科学家被曝处境尴尬，马斯克：可以考虑来我这里\n",
      "passage:OpenAI首席科学家兼联合创始人伊尔亚・苏茨克维目前正处于尴尬境地。上个月，他参与董事会投票解雇了CEO萨姆・奥特曼，但仅仅五天后，奥特曼在员工和投资者的强烈支持下重新上任。最近的一篇报道指出，苏茨克维目前似乎处于一种“迷茫”的状态，在OpenAI变得“隐形”。就在人们纷纷猜测苏茨克维的未来走向时，马斯克在社交媒体上公开表示，苏茨克维应该加入特斯拉或他的AI公司xAI。（IT之家）\n",
      "\n",
      "from:bang\n",
      "title:【OpenAI首席科学家处境尴尬，马斯克抛出橄榄枝】\n",
      "passage:OpenAI 首席科学家兼联合创始人伊尔亚・苏茨克维 (Ilya Sutskever) 目前正处于尴尬境地。上个月，他参与董事会投票解雇了 CEO 萨姆・阿尔特曼 (Sam Altman)，但仅仅五天后，阿尔特曼在员工和投资者的强烈支持下重新上任。 最近的一篇报道指出，苏茨克维目前似乎处于一种“迷茫”的状态，在 OpenAI 变得“隐形”。报道称，自阿尔特曼回归以来，苏茨克维就没有出现在 OpenAI 旧金山的办公室内。就在人们纷纷猜测苏茨克维的未来走向时，马斯克在社交媒体上公开表示，苏茨克维应该加入特斯拉或他的 AI 公司 xAI。（凤凰财经）\n",
      "\n",
      "##############################\n",
      "\n",
      "cluster 5:\n",
      "\n",
      "from:36kr\n",
      "title:欧盟就全球首个全面监管AI的法案达成初步协议\n",
      "passage:当地时间12月8日，欧洲议会、欧盟成员国和欧盟委员会三方就《人工智能法案》达成了临时协议，该法案预计会成为世界上第一部全面监管人工智能的法规。\n",
      "\n",
      "from:tencent\n",
      "title:39小时谈判！欧盟AI监管达成里程碑协议，直指ChatGPT和谷歌Bard\n",
      "passage:欧洲议会、欧盟成员国和欧盟委员会历时40小时谈判后，达成全球首部人工智能领域的全面监管法规草案《人工智能法案》。法案旨在全面监管AI，为技术开发和使用提供更好条件，对生成性AI工具实施一系列控制措施。法案草案仍需得到欧盟成员国和议会正式批准，预计明年初生效，两年后将全面实施。（华尔街见闻）\n",
      "\n",
      "##############################\n",
      "\n",
      "cluster 6:\n",
      "\n",
      "from:tencent\n",
      "title:刘强东内网发声：必须改变，否则没有出路！\n",
      "passage:京东创始人、董事局主席刘强东日前在公司内网回复员工评论称，“无论如何，自己都不会躺平，也希望兄弟们绝不躺平……京东基础依然在，相信我们一定会走出低谷。现在组织庞大臃肿低效，改变起来确实需要时间。”（晚点LatePost）\n",
      "\n",
      "from:bang\n",
      "title:【马云之后，刘强东也在内网发声：京东基础依然在，相信会走出谷底】\n",
      "passage:12月9日晚22点，京东创始人、董事局主席刘强东在公司内网回复员工评论称，“无论如何，我都不会躺平，也希望兄弟们绝不躺平……京东基础依然在，相信我们一定会走出低谷。任何一个人任何一家公司都会经历若干个顶峰和低谷才能成就伟大。” 就在11月底，马云在内网回复员工关于“拼多多市值赶上阿里”的帖子称，我坚信阿里会变，阿里会改。（上游新闻）\n",
      "\n",
      "##############################\n",
      "\n",
      "cluster 7:\n",
      "\n",
      "from:tencent\n",
      "title:英伟达CEO黄仁勋访问越南，计划在该国建芯片生产中心\n",
      "passage:当地时间10日，越南政府总理范明政与到访的英伟达CEO黄仁勋会面。今年9月，范明政在美国参观英伟达总部，并邀请黄仁勋尽快访问越南。\n",
      "范明政表示，目前，越南半导体行业约有6000名工程师。越南的目标是到2030年培养5万名高素质工程师，特别是半导体芯片设计专业人才。\n",
      "\n",
      "from:bang\n",
      "title:【英伟达CEO黄仁勋访问越南，计划在该国建芯片生产中心】据越南政府网站12月10日声明，当地时间10日，越南政府总理范明政与到访的英伟达CEO黄仁勋会面。今年9月，范明政在美国参观英伟达总部，并邀请黄仁勋尽快访问越南。范明政表示，目前，越南半导体行业约有6000名工程师。越南的目标是到2030年培养5万名高素质工程师，特别是半导体芯片设计专业人才。（新浪财经）\n",
      "passage:\n",
      "\n",
      "##############################\n",
      "\n",
      "cluster 8:\n",
      "\n",
      "from:tencent\n",
      "title:辛选正式任免：蓝山出任CEO，管倩不再担任CEO\n",
      "passage:辛选集团日前下发《关于辛选集团人员任免的通知》。《通知》提到，为进一步整合资源，提升业务运作效率和质量，经集团董事长授权，相关程序批准，任命宋铁牛（蓝山）为集团CEO，全面负责集团的日常管理工作，管倩不再担任集团CEO。（三言科技）\n",
      "\n",
      "from:bang\n",
      "title:【蓝山接替管倩成辛选集团新CEO】\n",
      "passage:辛选集团于9日下发《关于辛选集团人员任免的通知》。《通知》提到，为进一步整合资源，提升业务运作效率和质量，经集团董事长授权，相关程序批准，任命宋铁牛（蓝山）为集团CEO，全面负责集团的日常管理工作，管倩不再担任集团 CEO。公开资料显示，宋铁牛（蓝山）为辛选联合创始人之一，曾负责企业形象、宣传及项目合作投资等事务。今年3月初，辛巴曾在直播间宣布，合作五年的辛选四大合伙人\"分道扬镳\"。（新浪科技）\n",
      "\n",
      "##############################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 可视化聚类结果\n",
    "for label in clustering_res:\n",
    "    if label == -1:\n",
    "        # noisy points（未聚类的点），因此不展示\n",
    "        continue\n",
    "    print(f'cluster {label}:')\n",
    "    print()\n",
    "    for new in clustering_res[label]:\n",
    "        print(f'from:{new[0]}\\ntitle:{new[1]}\\npassage:{new[2]}')\n",
    "        print()\n",
    "    print('#' * 30)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e7ad4a-3619-4849-9828-e8484901c81d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f326440-20a7-4f30-a558-230c080dc9ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60863a8a-b5b5-4294-af21-f44ffc77f8d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
